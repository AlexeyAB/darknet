{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alexDarknet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/J-Thunderbolt/darknet/blob/master/alexDarknet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkCTWoxgeOtx",
        "colab_type": "code",
        "outputId": "8b070def-44cf-4901-f7f4-0fd6e71494bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# path \"/content/gdrive/My Drive/\"\n",
        "# !/usr/local/cuda/bin/nvcc --version\n",
        "\n",
        "# !sudo apt-get install vim\n",
        "# !sudo apt-get install tree\n",
        "# !sudo apt-get install nano\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "import random\n",
        "\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6I0H8gjbedYD",
        "colab_type": "code",
        "outputId": "9d6e987b-dd4b-4495-e9d2-ae61b89d9afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "!tar -xzvf /content/gdrive/My\\ Drive/sdarknet53/cuDNN/cudnn-10.0-linux-x64-v7.6.4.38.tgz -C /usr/local/\n",
        "!chmod a+r /usr/local/cuda/include/cudnn.h\n",
        "!cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#define CUDNN_MAJOR 7\n",
            "#define CUDNN_MINOR 6\n",
            "#define CUDNN_PATCHLEVEL 4\n",
            "--\n",
            "#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\n",
            "\n",
            "#include \"driver_types.h\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak8BzSNPf1X0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# os.chdir(\"/content/gdrive/My Drive/AlexDarknet/\")\n",
        "# !git clone https://github.com/AlexeyAB/darknet \n",
        "\n",
        "!chmod +x \"/content/gdrive/My Drive/AlexDarknet/darknet/darknet\"\n",
        "\n",
        "# os.chdir(\"/content/gdrive/My Drive/AlexDarknet/darknet\")\n",
        "# !make"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EEycb0KiZsp",
        "colab_type": "code",
        "outputId": "09c84f8a-c614-4ebf-e453-2639f64f7943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Copy img.zip file into VM\n",
        "os.chdir(\"/content/gdrive/My Drive/sdarknet53/\")\n",
        "!cp -rv \"/content/gdrive/My Drive/sdarknet53/img/dataset.zip\" /home/\n",
        "# Uncompress zipped file into darknet folder\n",
        "!unzip -q /home/dataset.zip -d /home/darknet/\n",
        "\n",
        "os.chdir(\"/home/darknet/\")\n",
        "!mkdir img\n",
        "\n",
        "!cp -rf /home/darknet/dataset/mustafa_1_2/mustafa_1_2_TL-folder/* /home/darknet/img/\n",
        "!cp -rf /home/darknet/dataset/mustafa_2_1/mustafa_2_1_TL-folder/* /home/darknet/img/\n",
        "!cp -rf /home/darknet/dataset/mustafa_2_2/mustafa_2_2_TL-folder/* /home/darknet/img/\n",
        "# !cp -rf /home/darknet/dataset/mustafa_1_2/mustafa_1_2_TL-folder/* /home/darknet/img/\n",
        "\n",
        "# !ls /home/darknet/dataset/mustafa_1_2 | head -n 10\n",
        "!ls /home/darknet/img/ | head -n 20"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mustafa_1_2_BR-100.jpg\n",
            "mustafa_1_2_BR-100.txt\n",
            "mustafa_1_2_BR-101.jpg\n",
            "mustafa_1_2_BR-101.txt\n",
            "mustafa_1_2_BR-102.jpg\n",
            "mustafa_1_2_BR-102.txt\n",
            "mustafa_1_2_BR-103.jpg\n",
            "mustafa_1_2_BR-103.txt\n",
            "mustafa_1_2_BR-104.jpg\n",
            "mustafa_1_2_BR-104.txt\n",
            "mustafa_1_2_BR-105.jpg\n",
            "mustafa_1_2_BR-105.txt\n",
            "mustafa_1_2_BR-106.jpg\n",
            "mustafa_1_2_BR-106.txt\n",
            "mustafa_1_2_BR-107.jpg\n",
            "mustafa_1_2_BR-107.txt\n",
            "mustafa_1_2_BR-108.jpg\n",
            "mustafa_1_2_BR-108.txt\n",
            "mustafa_1_2_BR-109.jpg\n",
            "mustafa_1_2_BR-109.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHS0FzaYL8xc",
        "colab_type": "code",
        "outputId": "2bc382da-4425-44d7-c10f-845277fc1f8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# !sort -V \"/content/gdrive/My Drive/AlexDarknet/darknet/train.txt\" > train.txt\n",
        "!head -n 32 \"/content/gdrive/My Drive/AlexDarknet/darknet/train.txt\"\n",
        "!cat \"/content/gdrive/My Drive/AlexDarknet/darknet/cfg/yolo_v3_spp_lstm.cfg\"\n",
        "!tail -n 25 \"/content/gdrive/My Drive/AlexDarknet/darknet/cfg/yolov3.cfg\""
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/darknet/img/mustafa_1_2_BR-1.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-2.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-3.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-4.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-5.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-6.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-7.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-8.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-9.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-10.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-11.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-12.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-13.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-14.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-15.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-16.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-17.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-18.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-19.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-20.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-21.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-22.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-23.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-24.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-25.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-26.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-27.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-28.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-29.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-30.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-31.jpg\n",
            "/home/darknet/img/mustafa_1_2_BR-32.jpg\n",
            "[net]\n",
            "# Testing\n",
            "#batch=1\n",
            "#subdivisions=1\n",
            "# Training\n",
            "batch=8\n",
            "subdivisions=8\n",
            "width=320\n",
            "height=320\n",
            "channels=3\n",
            "momentum=0.9\n",
            "decay=0.0005\n",
            "angle=0\n",
            "saturation = 1.5\n",
            "exposure = 1.5\n",
            "hue=.1\n",
            "\n",
            "\n",
            "track=1\n",
            "time_steps=4\t# for 8GB GPU\n",
            "#time_steps=2\t# for 4GB GPU\n",
            "augment_speed=3\n",
            "sequential_subdivisions=8\n",
            "\n",
            "learning_rate=0.001\n",
            "burn_in=1000\n",
            "max_batches = 4500000\n",
            "\n",
            "policy=sgdr\n",
            "sgdr_cycle=1000\n",
            "sgdr_mult=2\n",
            "steps=4000,6000,8000,9000\n",
            "#scales=1, 1, 0.1, 0.1\n",
            "seq_scales=0.5, 1, 0.5, 1\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=32\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=32\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "# Downsample\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=1024\n",
            "size=3\n",
            "stride=2\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=1024\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=1024\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=1024\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=1024\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[shortcut]\n",
            "from=-3\n",
            "activation=linear\n",
            "\n",
            "\n",
            "### SPP ###\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[maxpool]\n",
            "stride=1\n",
            "size=5\n",
            "\n",
            "[route]\n",
            "layers=-2\n",
            "\n",
            "[maxpool]\n",
            "stride=1\n",
            "size=9\n",
            "\n",
            "[route]\n",
            "layers=-4\n",
            "\n",
            "[maxpool]\n",
            "stride=1\n",
            "size=13\n",
            "\n",
            "[route]\n",
            "layers=-1,-3,-5,-7\n",
            "\n",
            "### End SPP ###\n",
            "\n",
            "\n",
            "###########\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[conv_lstm]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "pad=1\n",
            "output=256\n",
            "peephole=0\n",
            "#groups=4\n",
            "#state_constrain=512\n",
            "activation=leaky\n",
            "\n",
            "[conv_lstm]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "pad=1\n",
            "output=256\n",
            "peephole=0\n",
            "#groups=4\n",
            "#state_constrain=512\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers=-1,-3\n",
            "\n",
            "\n",
            "###########\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "\n",
            "########### to [yolo-3]\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[upsample]\n",
            "stride=2\n",
            "\n",
            "[route]\n",
            "layers = -1, 61\n",
            "\n",
            "###########\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[conv_lstm]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "pad=1\n",
            "output=128\n",
            "peephole=0\n",
            "#groups=4\n",
            "#state_constrain=512\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers=-1,-2\n",
            "\n",
            "###########\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "\n",
            "\n",
            "########### to [yolo-2]\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[upsample]\n",
            "stride=2\n",
            "\n",
            "[route]\n",
            "layers = -1, 36\n",
            "\n",
            "###########\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=64\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[conv_lstm]\n",
            "batch_normalize=1\n",
            "size=3\n",
            "pad=1\n",
            "output=64\n",
            "peephole=0\n",
            "#groups=4\n",
            "#state_constrain=512\n",
            "activation=leaky\n",
            "\n",
            "[route]\n",
            "layers=-1,-2\n",
            "\n",
            "###########\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=128\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "########### [yolo-1]\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=18\n",
            "activation=linear\n",
            "\n",
            "[yolo]\n",
            "mask = 0,1,2\n",
            "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
            "classes=1\n",
            "num=9\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=0\n",
            "\n",
            "\n",
            "\n",
            "########### [yolo-2]\n",
            "\n",
            "[route]\n",
            "layers = -12\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=256\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=18\n",
            "activation=linear\n",
            "\n",
            "[yolo]\n",
            "mask = 3,4,5\n",
            "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
            "classes=1\n",
            "num=9\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=0\n",
            "\n",
            "########### [yolo-3]\n",
            "\n",
            "[route]\n",
            "layers = -24\n",
            "\n",
            "[convolutional]\n",
            "batch_normalize=1\n",
            "filters=512\n",
            "size=3\n",
            "stride=1\n",
            "pad=1\n",
            "activation=leaky\n",
            "\n",
            "[convolutional]\n",
            "size=1\n",
            "stride=1\n",
            "pad=1\n",
            "filters=18\n",
            "activation=linear\n",
            "\n",
            "\n",
            "\n",
            "[yolo]\n",
            "mask = 6,7,8\n",
            "anchors = 10,13,  16,30,  33,23,  30,61,  62,45,  59,119,  116,90,  156,198,  373,326\n",
            "classes=1\n",
            "num=9\n",
            "jitter=.3\n",
            "ignore_thresh = .7\n",
            "truth_thresh = 1\n",
            "random=0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsTcyMJOiygZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_data_set(image_dir, test_size):\n",
        "\n",
        "    f_val = open(\"test.txt\", 'w')\n",
        "    f_train = open(\"train.txt\", 'w')\n",
        "\n",
        "    path, dirs, files = next(os.walk(image_dir))\n",
        "    data_size = len(files)\n",
        "\n",
        "    ind = 0\n",
        "    data_test_size = int(test_size * data_size)\n",
        "    test_array = random.sample(range(data_size), k=data_test_size)\n",
        "\n",
        "    for f in os.listdir(image_dir):\n",
        "        if(f.split(\".\")[1] == \"jpg\"):\n",
        "            ind += 1\n",
        "\n",
        "            if ind in test_array:\n",
        "                f_val.write(image_dir+'/'+f+'\\n')\n",
        "            else:\n",
        "                f_train.write(image_dir+'/'+f+'\\n')\n",
        "\n",
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  #plt.rcParams['figure.figsize'] = [10, 5]\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5-QSRI8izJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# os.chdir(\"/content/gdrive/My Drive/AlexDarknet/darknet\")\n",
        "# split_data_set(\"/home/darknet/img\", 0.0)\n",
        "# !head -n 10 /content/gdrive/My\\ Drive/sdarknet53/darknet/train.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7P1EmrKjI0a",
        "colab_type": "code",
        "outputId": "8fe5b386-a18b-401b-b35b-6a1c317a4eb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# os.chdir(\"/content/gdrive/My Drive/AlexDarknet/darknet\")\n",
        "# !./darknet detector calc_anchors \"/content/gdrive/My Drive/AlexDarknet/darknet/obj.data\" -num_of_clusters 9 -width 416 -height 416\n",
        "# !wget https://pjreddie.com/media/files/yolov3-spp.weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-12 10:22:21--  https://pjreddie.com/media/files/yolov3-spp.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 252209544 (241M) [application/octet-stream]\n",
            "Saving to: ‘yolov3-spp.weights’\n",
            "\n",
            "yolov3-spp.weights  100%[===================>] 240.53M  21.6MB/s    in 12s     \n",
            "\n",
            "2019-11-12 10:22:34 (19.9 MB/s) - ‘yolov3-spp.weights’ saved [252209544/252209544]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXdm7AJjxUI5",
        "colab_type": "code",
        "outputId": "931b2daf-7a40-479f-d88a-6abc577bfe76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(\"/content/gdrive/My Drive/AlexDarknet/darknet\")\n",
        "!cat ./obj.data\n",
        "!./darknet detector train ./obj.data ./cfg/yolo_v3_spp_lstm.cfg /content/gdrive/My\\ Drive/AlexDarknet/darknet/yolov3-spp.weights"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classes = 1\n",
            "train  = ./train.txt\n",
            "valid  = ./test.txt\n",
            "names = ./obj.names\n",
            "backup = ./backup\n",
            "yolo_v3_spp_lstm\n",
            "   layer   filters  size/strd(dil)      input                output\n",
            "   0 conv     32       3 x 3/ 1    320 x 320 x   3 ->  320 x 320 x  32 0.177 BF\n",
            "   1 conv     64       3 x 3/ 2    320 x 320 x  32 ->  160 x 160 x  64 0.944 BF\n",
            "   2 conv     32       1 x 1/ 1    160 x 160 x  64 ->  160 x 160 x  32 0.105 BF\n",
            "   3 conv     64       3 x 3/ 1    160 x 160 x  32 ->  160 x 160 x  64 0.944 BF\n",
            "   4 Shortcut Layer: 1\n",
            "   5 conv    128       3 x 3/ 2    160 x 160 x  64 ->   80 x  80 x 128 0.944 BF\n",
            "   6 conv     64       1 x 1/ 1     80 x  80 x 128 ->   80 x  80 x  64 0.105 BF\n",
            "   7 conv    128       3 x 3/ 1     80 x  80 x  64 ->   80 x  80 x 128 0.944 BF\n",
            "   8 Shortcut Layer: 5\n",
            "   9 conv     64       1 x 1/ 1     80 x  80 x 128 ->   80 x  80 x  64 0.105 BF\n",
            "  10 conv    128       3 x 3/ 1     80 x  80 x  64 ->   80 x  80 x 128 0.944 BF\n",
            "  11 Shortcut Layer: 8\n",
            "  12 conv    256       3 x 3/ 2     80 x  80 x 128 ->   40 x  40 x 256 0.944 BF\n",
            "  13 conv    128       1 x 1/ 1     40 x  40 x 256 ->   40 x  40 x 128 0.105 BF\n",
            "  14 conv    256       3 x 3/ 1     40 x  40 x 128 ->   40 x  40 x 256 0.944 BF\n",
            "  15 Shortcut Layer: 12\n",
            "  16 conv    128       1 x 1/ 1     40 x  40 x 256 ->   40 x  40 x 128 0.105 BF\n",
            "  17 conv    256       3 x 3/ 1     40 x  40 x 128 ->   40 x  40 x 256 0.944 BF\n",
            "  18 Shortcut Layer: 15\n",
            "  19 conv    128       1 x 1/ 1     40 x  40 x 256 ->   40 x  40 x 128 0.105 BF\n",
            "  20 conv    256       3 x 3/ 1     40 x  40 x 128 ->   40 x  40 x 256 0.944 BF\n",
            "  21 Shortcut Layer: 18\n",
            "  22 conv    128       1 x 1/ 1     40 x  40 x 256 ->   40 x  40 x 128 0.105 BF\n",
            "  23 conv    256       3 x 3/ 1     40 x  40 x 128 ->   40 x  40 x 256 0.944 BF\n",
            "  24 Shortcut Layer: 21\n",
            "  25 conv    128       1 x 1/ 1     40 x  40 x 256 ->   40 x  40 x 128 0.105 BF\n",
            "  26 conv    256       3 x 3/ 1     40 x  40 x 128 ->   40 x  40 x 256 0.944 BF\n",
            "  27 Shortcut Layer: 24\n",
            "  28 conv    128       1 x 1/ 1     40 x  40 x 256 ->   40 x  40 x 128 0.105 BF\n",
            "  29 conv    256       3 x 3/ 1     40 x  40 x 128 ->   40 x  40 x 256 0.944 BF\n",
            "  30 Shortcut Layer: 27\n",
            "  31 conv    128       1 x 1/ 1     40 x  40 x 256 ->   40 x  40 x 128 0.105 BF\n",
            "  32 conv    256       3 x 3/ 1     40 x  40 x 128 ->   40 x  40 x 256 0.944 BF\n",
            "  33 Shortcut Layer: 30\n",
            "  34 conv    128       1 x 1/ 1     40 x  40 x 256 ->   40 x  40 x 128 0.105 BF\n",
            "  35 conv    256       3 x 3/ 1     40 x  40 x 128 ->   40 x  40 x 256 0.944 BF\n",
            "  36 Shortcut Layer: 33\n",
            "  37 conv    512       3 x 3/ 2     40 x  40 x 256 ->   20 x  20 x 512 0.944 BF\n",
            "  38 conv    256       1 x 1/ 1     20 x  20 x 512 ->   20 x  20 x 256 0.105 BF\n",
            "  39 conv    512       3 x 3/ 1     20 x  20 x 256 ->   20 x  20 x 512 0.944 BF\n",
            "  40 Shortcut Layer: 37\n",
            "  41 conv    256       1 x 1/ 1     20 x  20 x 512 ->   20 x  20 x 256 0.105 BF\n",
            "  42 conv    512       3 x 3/ 1     20 x  20 x 256 ->   20 x  20 x 512 0.944 BF\n",
            "  43 Shortcut Layer: 40\n",
            "  44 conv    256       1 x 1/ 1     20 x  20 x 512 ->   20 x  20 x 256 0.105 BF\n",
            "  45 conv    512       3 x 3/ 1     20 x  20 x 256 ->   20 x  20 x 512 0.944 BF\n",
            "  46 Shortcut Layer: 43\n",
            "  47 conv    256       1 x 1/ 1     20 x  20 x 512 ->   20 x  20 x 256 0.105 BF\n",
            "  48 conv    512       3 x 3/ 1     20 x  20 x 256 ->   20 x  20 x 512 0.944 BF\n",
            "  49 Shortcut Layer: 46\n",
            "  50 conv    256       1 x 1/ 1     20 x  20 x 512 ->   20 x  20 x 256 0.105 BF\n",
            "  51 conv    512       3 x 3/ 1     20 x  20 x 256 ->   20 x  20 x 512 0.944 BF\n",
            "  52 Shortcut Layer: 49\n",
            "  53 conv    256       1 x 1/ 1     20 x  20 x 512 ->   20 x  20 x 256 0.105 BF\n",
            "  54 conv    512       3 x 3/ 1     20 x  20 x 256 ->   20 x  20 x 512 0.944 BF\n",
            "  55 Shortcut Layer: 52\n",
            "  56 conv    256       1 x 1/ 1     20 x  20 x 512 ->   20 x  20 x 256 0.105 BF\n",
            "  57 conv    512       3 x 3/ 1     20 x  20 x 256 ->   20 x  20 x 512 0.944 BF\n",
            "  58 Shortcut Layer: 55\n",
            "  59 conv    256       1 x 1/ 1     20 x  20 x 512 ->   20 x  20 x 256 0.105 BF\n",
            "  60 conv    512       3 x 3/ 1     20 x  20 x 256 ->   20 x  20 x 512 0.944 BF\n",
            "  61 Shortcut Layer: 58\n",
            "  62 conv   1024       3 x 3/ 2     20 x  20 x 512 ->   10 x  10 x1024 0.944 BF\n",
            "  63 conv    512       1 x 1/ 1     10 x  10 x1024 ->   10 x  10 x 512 0.105 BF\n",
            "  64 conv   1024       3 x 3/ 1     10 x  10 x 512 ->   10 x  10 x1024 0.944 BF\n",
            "  65 Shortcut Layer: 62\n",
            "  66 conv    512       1 x 1/ 1     10 x  10 x1024 ->   10 x  10 x 512 0.105 BF\n",
            "  67 conv   1024       3 x 3/ 1     10 x  10 x 512 ->   10 x  10 x1024 0.944 BF\n",
            "  68 Shortcut Layer: 65\n",
            "  69 conv    512       1 x 1/ 1     10 x  10 x1024 ->   10 x  10 x 512 0.105 BF\n",
            "  70 conv   1024       3 x 3/ 1     10 x  10 x 512 ->   10 x  10 x1024 0.944 BF\n",
            "  71 Shortcut Layer: 68\n",
            "  72 conv    512       1 x 1/ 1     10 x  10 x1024 ->   10 x  10 x 512 0.105 BF\n",
            "  73 conv   1024       3 x 3/ 1     10 x  10 x 512 ->   10 x  10 x1024 0.944 BF\n",
            "  74 Shortcut Layer: 71\n",
            "  75 conv    512       1 x 1/ 1     10 x  10 x1024 ->   10 x  10 x 512 0.105 BF\n",
            "  76 max                5x 5/ 1     10 x  10 x 512 ->   10 x  10 x 512 0.001 BF\n",
            "  77 route  75\n",
            "  78 max                9x 9/ 1     10 x  10 x 512 ->   10 x  10 x 512 0.004 BF\n",
            "  79 route  75\n",
            "  80 max               13x13/ 1     10 x  10 x 512 ->   10 x  10 x 512 0.009 BF\n",
            "  81 route  80 78 76 74\n",
            "  82 conv    512       1 x 1/ 1     10 x  10 x2560 ->   10 x  10 x 512 0.262 BF\n",
            "  83 conv    256       1 x 1/ 1     10 x  10 x 512 ->   10 x  10 x 256 0.026 BF\n",
            "  84 CONV_LSTM Layer: 10 x 10 x 256 image, 256 filters\n",
            "conv    256       3 x 3/ 1     10 x  10 x 256 ->   10 x  10 x 256 0.118 BF\n",
            "conv    256       3 x 3/ 1     10 x  10 x 256 ->   10 x  10 x 256 0.118 BF\n",
            "conv    256       3 x 3/ 1     10 x  10 x 256 ->   10 x  10 x 256 0.118 BF\n",
            "conv    256       3 x 3/ 1     10 x  10 x 256 ->   10 x  10 x 256 0.118 BF\n",
            "conv    256       3 x 3/ 1     10 x  10 x 256 ->   10 x  10 x 256 0.118 BF\n",
            "conv    256       3 x 3/ 1     10 x  10 x 256 ->   10 x  10 x 256 0.118 BF\n",
            "conv    256       3 x 3/ 1     10 x  10 x 256 ->   10 x  10 x 256 0.118 BF\n",
            "conv    256       3 x 3/ 1     10 x  10 x 256 ->   10 x  10 x 256 0.118 BF\n",
            "  85 CONV_LSTM Layer: 10 x 10 x 256 image, 256 filters\n",
            "conv    256       3 x 3/ 1     10 x  10 x 256 ->   10 x  10 x 256 0.118 BF\n",
            "conv    256       3 x 3/ 1     10 x  10 x 256 ->   10 x  10 x 256 0.118 BF\n",
            "conv    256       3 x 3/ 1     10 x  10 x 256 ->   10 x  10 x 256 0.118 BF\n",
            "conv    256       3 x 3/ 1     10 x  10 x 256 ->   10 x  10 x 256 0.118 BF\n",
            "conv    256       3 x 3/ 1     10 x  10 x 256 ->   10 x  10 x 256 0.118 BF\n",
            "conv    256       3 x 3/ 1     10 x  10 x 256 ->   10 x  10 x 256 0.118 BF\n",
            "conv    256       3 x 3/ 1     10 x  10 x 256 ->   10 x  10 x 256 0.118 BF\n",
            "conv    256       3 x 3/ 1     10 x  10 x 256 ->   10 x  10 x 256 0.118 BF\n",
            "  86 route  85 83\n",
            "  87 conv    512       1 x 1/ 1     10 x  10 x 512 ->   10 x  10 x 512 0.052 BF\n",
            "  88 conv    256       1 x 1/ 1     10 x  10 x 512 ->   10 x  10 x 256 0.026 BF\n",
            "  89 upsample                 2x    10 x  10 x 256 ->   20 x  20 x 256\n",
            "  90 route  89 61\n",
            "  91 conv    256       1 x 1/ 1     20 x  20 x 768 ->   20 x  20 x 256 0.157 BF\n",
            "  92 conv    128       1 x 1/ 1     20 x  20 x 256 ->   20 x  20 x 128 0.026 BF\n",
            "  93 CONV_LSTM Layer: 20 x 20 x 128 image, 128 filters\n",
            "conv    128       3 x 3/ 1     20 x  20 x 128 ->   20 x  20 x 128 0.118 BF\n",
            "conv    128       3 x 3/ 1     20 x  20 x 128 ->   20 x  20 x 128 0.118 BF\n",
            "conv    128       3 x 3/ 1     20 x  20 x 128 ->   20 x  20 x 128 0.118 BF\n",
            "conv    128       3 x 3/ 1     20 x  20 x 128 ->   20 x  20 x 128 0.118 BF\n",
            "conv    128       3 x 3/ 1     20 x  20 x 128 ->   20 x  20 x 128 0.118 BF\n",
            "conv    128       3 x 3/ 1     20 x  20 x 128 ->   20 x  20 x 128 0.118 BF\n",
            "conv    128       3 x 3/ 1     20 x  20 x 128 ->   20 x  20 x 128 0.118 BF\n",
            "conv    128       3 x 3/ 1     20 x  20 x 128 ->   20 x  20 x 128 0.118 BF\n",
            "  94 route  93 92\n",
            "  95 conv    256       1 x 1/ 1     20 x  20 x 256 ->   20 x  20 x 256 0.052 BF\n",
            "  96 conv    256       1 x 1/ 1     20 x  20 x 256 ->   20 x  20 x 256 0.052 BF\n",
            "  97 upsample                 2x    20 x  20 x 256 ->   40 x  40 x 256\n",
            "  98 route  97 36\n",
            "  99 conv    128       1 x 1/ 1     40 x  40 x 512 ->   40 x  40 x 128 0.210 BF\n",
            " 100 conv     64       1 x 1/ 1     40 x  40 x 128 ->   40 x  40 x  64 0.026 BF\n",
            " 101 CONV_LSTM Layer: 40 x 40 x 64 image, 64 filters\n",
            "conv     64       3 x 3/ 1     40 x  40 x  64 ->   40 x  40 x  64 0.118 BF\n",
            "conv     64       3 x 3/ 1     40 x  40 x  64 ->   40 x  40 x  64 0.118 BF\n",
            "conv     64       3 x 3/ 1     40 x  40 x  64 ->   40 x  40 x  64 0.118 BF\n",
            "conv     64       3 x 3/ 1     40 x  40 x  64 ->   40 x  40 x  64 0.118 BF\n",
            "conv     64       3 x 3/ 1     40 x  40 x  64 ->   40 x  40 x  64 0.118 BF\n",
            "conv     64       3 x 3/ 1     40 x  40 x  64 ->   40 x  40 x  64 0.118 BF\n",
            "conv     64       3 x 3/ 1     40 x  40 x  64 ->   40 x  40 x  64 0.118 BF\n",
            "conv     64       3 x 3/ 1     40 x  40 x  64 ->   40 x  40 x  64 0.118 BF\n",
            " 102 route  101 100\n",
            " 103 conv    128       1 x 1/ 1     40 x  40 x 128 ->   40 x  40 x 128 0.052 BF\n",
            " 104 conv    128       3 x 3/ 1     40 x  40 x 128 ->   40 x  40 x 128 0.472 BF\n",
            " 105 conv     18       1 x 1/ 1     40 x  40 x 128 ->   40 x  40 x  18 0.007 BF\n",
            " 106 yolo\n",
            "[yolo] params: iou loss: mse, iou_norm: 0.75, cls_norm: 1.00, scale_x_y: 1.00\n",
            " 107 route  95\n",
            " 108 conv    256       3 x 3/ 1     20 x  20 x 256 ->   20 x  20 x 256 0.472 BF\n",
            " 109 conv     18       1 x 1/ 1     20 x  20 x 256 ->   20 x  20 x  18 0.004 BF\n",
            " 110 yolo\n",
            "[yolo] params: iou loss: mse, iou_norm: 0.75, cls_norm: 1.00, scale_x_y: 1.00\n",
            " 111 route  87\n",
            " 112 conv    512       3 x 3/ 1     10 x  10 x 512 ->   10 x  10 x 512 0.472 BF\n",
            " 113 conv     18       1 x 1/ 1     10 x  10 x 512 ->   10 x  10 x  18 0.002 BF\n",
            " 114 yolo\n",
            "[yolo] params: iou loss: mse, iou_norm: 0.75, cls_norm: 1.00, scale_x_y: 1.00\n",
            "Total BFLOPS 35.281 \n",
            "Loading weights from /content/gdrive/My Drive/AlexDarknet/darknet/yolov3-spp.weights...\n",
            " seen 64 \n",
            "Done! Loaded 115 layers from weights-file \n",
            "Learning Rate: 0.001, Momentum: 0.9, Decay: 0.0005\n",
            "\n",
            " Tracking! batch = 4, subdiv = 8, time_steps = 4, mini_batch = 1 \n",
            " sequential_subdivisions = 2, sequence = 4 \n",
            "Loaded: 0.879470 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}